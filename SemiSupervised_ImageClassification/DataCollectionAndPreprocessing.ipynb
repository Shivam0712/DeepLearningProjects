{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection and Preprocessing\n",
    "\n",
    "This notebook is divided into 5 sections:\n",
    "\n",
    "1. Collect Data\n",
    "2. Create Dtaa For Transfer Learning\n",
    "3. Create Augmented\n",
    "4. Create Data For SemiSupervised Learning\n",
    "5. Create inference data\n",
    "6. Create directories for plots, logs and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Data\n",
    "\n",
    "1. Here we collecte data from given URL.\n",
    "2. Unzip them and delete the zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data URL\n",
    "URL = \\\n",
    "\"https://he-public-data.s3-ap-southeast-1.amazonaws.com/HE_Challenge_data.zip\"\n",
    "\n",
    "# download data\n",
    "os.system(\"curl -O \"+URL )\n",
    "\n",
    "# unzip data\n",
    "os.system(\"unzip HE_Challenge_data.zip\")\n",
    "\n",
    "# delete Zip file\n",
    "os.remove(\"HE_Challenge_data.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data for Transfer Learning\n",
    "\n",
    "1. Here we split the original train data into 80% Train and 20% Valid data using stratified random sampling.\n",
    "2. Also we segregate images into different directories based on their categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path\n",
    "path = os.getcwd()\n",
    "\n",
    "# create directory for Transfer learning data\n",
    "os.mkdir(path+'/data/data_TL/')\n",
    "\n",
    "# create directory for train data\n",
    "os.mkdir(path+'/data/data_TL/train')\n",
    "\n",
    "# create directory for val data\n",
    "os.mkdir(path+'/data/data_TL/val')\n",
    "\n",
    "# import train information\n",
    "df_train = pd.read_csv(path+'/data/train.csv')\n",
    "\n",
    "# create directories for different categories in train and val folders\n",
    "for i in df_train.category.unique():\n",
    "    # create directory in train\n",
    "    os.mkdir(path+'/data/data_TL/train/'+str(i)+'/')\n",
    "    # create directory in val\n",
    "    os.mkdir(path+'/data/data_TL/val/'+str(i)+'/')\n",
    "\n",
    "# stratified random sampling to split data b/w train and val\n",
    "for i in df_train.category.unique():\n",
    "    \n",
    "    # make list of images belonging t o the category\n",
    "    lis = list(df_train[df_train['category']==i]['image_id'])\n",
    "    \n",
    "    # randomly shuffle the list\n",
    "    random.seed(i)\n",
    "    random.shuffle(lis)\n",
    "    \n",
    "    # get list of training images\n",
    "    t_lis = lis[0:int(len(lis)*0.8)]\n",
    "    \n",
    "    # copy training images\n",
    "    for j in t_lis:\n",
    "        shutil.copyfile(path+'/data/train/'+str(j)+'.jpg', \\\n",
    "                        path+'/data/data_TL/train/'+str(i)+'/'+str(j)+'.jpg')\n",
    "    # get list of validation images\n",
    "    v_lis = lis[int(len(lis)*0.8):]\n",
    "    \n",
    "    # copy training images\n",
    "    for j in v_lis:\n",
    "        shutil.copyfile(path+'/data/train/'+str(j)+'.jpg', \\\n",
    "                        path+'/data/data_TL/val/'+str(i)+'/'+str(j)+'.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Augmented Data\n",
    "\n",
    "1. Here we take all images from train.\n",
    "2. Rotate them randomly at 3 different angles.\n",
    "3. Then split the data into 80% Train and 20% Valid data using stratified random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path\n",
    "path = os.getcwd()\n",
    "\n",
    "# create directory for Transfer learning data\n",
    "os.mkdir(path+'/data/data_Aug/')\n",
    "\n",
    "# create directory for train data\n",
    "os.mkdir(path+'/data/data_Aug/train')\n",
    "\n",
    "# create directory for val data\n",
    "os.mkdir(path+'/data/data_Aug/val')\n",
    "\n",
    "# create a temporary directory named aug\n",
    "os.mkdir(path+'/data/data_Aug/aug')\n",
    "\n",
    "# import train information\n",
    "df_train = pd.read_csv(path+'/data/train.csv')\n",
    "\n",
    "# create directories for different categories in train and val folders\n",
    "for i in df_train.category.unique():\n",
    "    # create directory in train\n",
    "    os.mkdir(path+'/data/data_Aug/train/'+str(i)+'/')\n",
    "    # create directory in val\n",
    "    os.mkdir(path+'/data/data_Aug/val/'+str(i)+'/')\n",
    "    # create directory in aug\n",
    "    os.mkdir(path+'/data/data_Aug/aug/'+str(i)+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified random sampling to split data b/w train and val\n",
    "for i in df_train.category.unique():\n",
    "    \n",
    "    # make list of images belonging t o the category\n",
    "    lis = list(df_train[df_train['category']==i]['image_id'])\n",
    "    \n",
    "    # augment all images and store in aug\n",
    "    for j in lis:\n",
    "        \n",
    "        # open image and save in aug\n",
    "        img = Image.open(path+'/data/train/'+str(j)+'.jpg')\n",
    "        img.save(path+'/data/data_Aug/aug/'+str(i)+'/0_'+str(j)+'.jpg')        \n",
    "        \n",
    "        # randomly choose 4 angles to flip data\n",
    "        lis_angle = [45,90,135,180,225,270,315]\n",
    "        random.seed(j)\n",
    "        random.shuffle(lis_angle)\n",
    "        # rotate and save image\n",
    "        for k in lis_angle[0:4]:\n",
    "            rot = img.rotate(k)\n",
    "            rot.save(path+'/data/data_Aug/aug/'+str(i)+\\\n",
    "                     '/'+str(k)+'_'+str(j)+'.jpg')\n",
    "        \n",
    "    # list of all images in aug folder\n",
    "    lis = list(os.listdir(path+'/data/data_Aug/aug/'+str(i)+'/'))\n",
    "    \n",
    "    # randomly shuffle the list\n",
    "    random.seed(i)\n",
    "    random.shuffle(lis)\n",
    "    \n",
    "    # get list of training images\n",
    "    t_lis = lis[0:int(len(lis)*0.8)]\n",
    "    \n",
    "    # copy training images\n",
    "    for j in t_lis:\n",
    "        if '.jpg' in j:\n",
    "            shutil.copyfile(path+'/data/data_Aug/aug/'+str(i)+'/'+j,\\\n",
    "                            path+'/data/data_Aug/train/'+str(i)+'/'+j)\n",
    "    \n",
    "    # get list of validation images\n",
    "    v_lis = lis[int(len(lis)*0.8):]\n",
    "    \n",
    "    # copy training images\n",
    "    for j in v_lis:\n",
    "        if '.jpg' in j:\n",
    "            shutil.copyfile(path+'/data/data_Aug/aug/'+str(i)+'/'+j,\\\n",
    "                            path+'/data/data_Aug/val/'+str(i)+'/'+j)\n",
    "\n",
    "# delete aug from data_Aug\n",
    "shutil.rmtree(path+'/data/data_Aug/aug/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data for Semi Supervised Learning\n",
    "\n",
    "1. Here we use all images from train and test.\n",
    "2. Invert them to make two categories: Upright and Inverted.\n",
    "3. Then split the data in these two categories into 80% Train and 20% Valid data using stratified random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path\n",
    "path = os.getcwd()\n",
    "\n",
    "# create directory for Semi Supervised learning data\n",
    "os.mkdir(path+'/data/data_SSL/')\n",
    "\n",
    "# create directory for train data\n",
    "os.mkdir(path+'/data/data_SSL/train')\n",
    "\n",
    "# create directory for val data\n",
    "os.mkdir(path+'/data/data_SSL/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directories for different categories in train and val folders\n",
    "for i in ['u', 'r']:\n",
    "    # create directory in train\n",
    "    os.mkdir(path+'/data/data_SSL/train/'+str(i)+'/')\n",
    "    # create directory in val\n",
    "    os.mkdir(path+'/data/data_SSL/val/'+str(i)+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of train images\n",
    "lis_train = list(os.listdir(path+'/data/train/'))\n",
    "\n",
    "# make list of test images\n",
    "lis_test = list(os.listdir(path+'/data/test/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split the original images and save in 'u' directory:\n",
    "\n",
    "# randomly shuffle the list\n",
    "random.seed(199)\n",
    "random.shuffle(lis_train)\n",
    "random.shuffle(lis_test)\n",
    "\n",
    "# get list of training images\n",
    "t_lis_train = lis_train[0:int(len(lis_train)*0.8)]\n",
    "t_lis_test = lis_test[0:int(len(lis_test)*0.8)]\n",
    "\n",
    "# copy training images\n",
    "for j in t_lis_train:\n",
    "    if '.jpg' in j:\n",
    "        shutil.copyfile(path+'/data/train/'+j, \\\n",
    "                        path+'/data/data_SSL/train/u/0_'+j)\n",
    "for j in t_lis_test:\n",
    "    if '.jpg' in j:\n",
    "        shutil.copyfile(path+'/data/test/'+j, \\\n",
    "                        path+'/data/data_SSL/train/u/0_'+j)\n",
    "\n",
    "# get list of val images\n",
    "v_lis_train = lis_train[int(len(lis_train)*0.8):]\n",
    "v_lis_test = lis_test[int(len(lis_test)*0.8):]\n",
    "\n",
    "# copy validation images\n",
    "for j in v_lis_train:\n",
    "    if '.jpg' in j:\n",
    "        shutil.copyfile(path+'/data/train/'+j, \\\n",
    "                        path+'/data/data_SSL/val/u/0_'+j)\n",
    "for j in v_lis_test:\n",
    "    if '.jpg' in j:\n",
    "        shutil.copyfile(path+'/data/test/'+j, \\\n",
    "                        path+'/data/data_SSL/val/u/0_'+j)\n",
    "    \n",
    "### split the rotated images and save in 'r' directory:\n",
    "\n",
    "# randomly shuffle the list\n",
    "random.seed(299)\n",
    "random.shuffle(lis_train)\n",
    "random.shuffle(lis_test)\n",
    "\n",
    "# get list of training images\n",
    "t_lis_train = lis_train[0:int(len(lis_train)*0.8)]\n",
    "t_lis_test = lis_test[0:int(len(lis_test)*0.8)]\n",
    "\n",
    "# copy training images\n",
    "for j in t_lis_train:\n",
    "    if '.jpg' in j:\n",
    "        img = Image.open(path+'/data/train/'+j)\n",
    "        rot = img.rotate(180)\n",
    "        rot.save(path+'/data/data_SSL/train/r/1_'+j)\n",
    "for j in t_lis_test:\n",
    "    if '.jpg' in j:\n",
    "        img = Image.open(path+'/data/test/'+j)\n",
    "        rot = img.rotate(180)\n",
    "        rot.save(path+'/data/data_SSL/train/r/1_'+j)\n",
    "\n",
    "# get list of val images\n",
    "v_lis_train = lis_train[int(len(lis_train)*0.8):]\n",
    "v_lis_test = lis_test[int(len(lis_test)*0.8):]\n",
    "\n",
    "# copy validation images\n",
    "for j in v_lis_train:\n",
    "    if '.jpg' in j:\n",
    "        img = Image.open(path+'/data/train/'+j)\n",
    "        rot = img.rotate(180)\n",
    "        rot.save(path+'/data/data_SSL/val/r/1_'+j)    \n",
    "for j in v_lis_test:\n",
    "    if '.jpg' in j:\n",
    "        img = Image.open(path+'/data/test/'+j)\n",
    "        rot = img.rotate(180)\n",
    "        rot.save(path+'/data/data_SSL/val/r/1_'+j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Inference Data\n",
    "\n",
    "Simply copy images in data/test/ folder into data/inference/test/.\n",
    "\n",
    "We do this to make it compatible for pytorch dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/skp454/SemiSupervised_Image_Classification/data/inference/test/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get path\n",
    "path = os.getcwd()\n",
    "\n",
    "# create directory for inference\n",
    "os.mkdir(path+'/data/inference/')\n",
    "\n",
    "# copy images from test to inference\n",
    "shutil.copytree(path+'/data/test/', path+'/data/inference/test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Other Useful Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path\n",
    "path = os.getcwd()\n",
    "\n",
    "# create directory for plots\n",
    "os.mkdir(path+'/data/plots/')\n",
    "\n",
    "# create directory for logs\n",
    "os.mkdir(path+'/data/logs/')\n",
    "\n",
    "# create directory for models\n",
    "os.mkdir(path+'/data/models/')\n",
    "\n",
    "# create directory for outputs\n",
    "os.mkdir(path+'/data/outputs/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
